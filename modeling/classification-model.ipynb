{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Model\n",
    "- Merge covers, random songs, and augmented songs datasets.\n",
    "- Set up for doing deep learning classifier from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "from IPython.display import Audio, display\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle as pkl\n",
    "import base64\n",
    "import time\n",
    "import urllib.parse\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from requests.exceptions import ReadTimeout\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift, AddGaussianSNR, ClippingDistortion, Gain\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Wav2Vec2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df = pd.read_pickle('/Users/reggiebain/erdos/song-similarity-erdos-old/data/augmented_audio/batch_1_augmented.pkl')\n",
    "cover_df = pd.read_pickle('/Users/reggiebain/erdos/song-similarity-erdos-old/data/test_set_covers.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>anchors</th>\n",
       "      <th>positives</th>\n",
       "      <th>negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Claudette</td>\n",
       "      <td>everly_brothers</td>\n",
       "      <td>The_Fabulous_Style_of</td>\n",
       "      <td>01-Claudette</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -61.775627, -48.010227,...</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -53.419292, -39.97673, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I_Don_t_Want_To_Miss_A_Thing</td>\n",
       "      <td>aerosmith</td>\n",
       "      <td>Armageddon_Original_Soundtrack_</td>\n",
       "      <td>01-I_Don_t_Want_To_Miss_A_Thing</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -79.25159, -56.510735, ...</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...</td>\n",
       "      <td>[[-80.0, -80.0, -80.0, -58.83052, -51.61307, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     song_title           artist  \\\n",
       "0                     Claudette  everly_brothers   \n",
       "1  I_Don_t_Want_To_Miss_A_Thing        aerosmith   \n",
       "\n",
       "                             album                             song  \\\n",
       "0            The_Fabulous_Style_of                     01-Claudette   \n",
       "1  Armageddon_Original_Soundtrack_  01-I_Don_t_Want_To_Miss_A_Thing   \n",
       "\n",
       "                                             anchors  \\\n",
       "0  [[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...   \n",
       "1  [[-80.0, -80.0, -80.0, -79.25159, -56.510735, ...   \n",
       "\n",
       "                                           positives  \\\n",
       "0  [[-80.0, -80.0, -80.0, -61.775627, -48.010227,...   \n",
       "1  [[-80.0, -80.0, -80.0, -80.0, -80.0, -80.0, -8...   \n",
       "\n",
       "                                           negatives  \n",
       "0  [[-80.0, -80.0, -80.0, -53.419292, -39.97673, ...  \n",
       "1  [[-80.0, -80.0, -80.0, -58.83052, -51.61307, -...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cover_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>name</th>\n",
       "      <th>artist</th>\n",
       "      <th>spotify_preview_url</th>\n",
       "      <th>spotify_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>genre</th>\n",
       "      <th>year</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>...</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>processed_audio</th>\n",
       "      <th>augmented_audio</th>\n",
       "      <th>diff_processed_audio</th>\n",
       "      <th>diff_artist</th>\n",
       "      <th>diff_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>TRFNPIK128F9317759</td>\n",
       "      <td>Limelight</td>\n",
       "      <td>Rush</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/6b5b71fc9762eda2...</td>\n",
       "      <td>0dnz7bSs3txd9nGY9e3Mlf</td>\n",
       "      <td>classic_rock, hard_rock, 80s, progressive_rock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2006</td>\n",
       "      <td>260066</td>\n",
       "      <td>0.579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.795</td>\n",
       "      <td>131.097</td>\n",
       "      <td>3</td>\n",
       "      <td>([-0.1274366, -0.21459332, -0.023305148, -0.08...</td>\n",
       "      <td>([-0.18257691, -0.3222155, -0.12718868, -0.017...</td>\n",
       "      <td>([-0.09010448, -0.13527939, -0.14203383, -0.09...</td>\n",
       "      <td>Mr. Big</td>\n",
       "      <td>To Be With You</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>TRWPWPE128F92CB675</td>\n",
       "      <td>Friends Will Be Friends</td>\n",
       "      <td>Queen</td>\n",
       "      <td>https://p.scdn.co/mp3-preview/771fbc667792ab31...</td>\n",
       "      <td>0nvIhBnscX9w7P2yrqxB6K</td>\n",
       "      <td>rock, classic_rock, hard_rock, 80s, british</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986</td>\n",
       "      <td>247840</td>\n",
       "      <td>0.438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.347</td>\n",
       "      <td>75.054</td>\n",
       "      <td>3</td>\n",
       "      <td>([0.09164546, 0.12546735, 0.06996889, 0.048958...</td>\n",
       "      <td>([0.080816284, 0.06832799, 0.08953604, 0.08095...</td>\n",
       "      <td>([-0.059521385, -0.09814703, 0.0005738288, 0.0...</td>\n",
       "      <td>Eric Clapton</td>\n",
       "      <td>Alberta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                     name artist  \\\n",
       "10000  TRFNPIK128F9317759                Limelight   Rush   \n",
       "10001  TRWPWPE128F92CB675  Friends Will Be Friends  Queen   \n",
       "\n",
       "                                     spotify_preview_url  \\\n",
       "10000  https://p.scdn.co/mp3-preview/6b5b71fc9762eda2...   \n",
       "10001  https://p.scdn.co/mp3-preview/771fbc667792ab31...   \n",
       "\n",
       "                   spotify_id                                            tags  \\\n",
       "10000  0dnz7bSs3txd9nGY9e3Mlf  classic_rock, hard_rock, 80s, progressive_rock   \n",
       "10001  0nvIhBnscX9w7P2yrqxB6K     rock, classic_rock, hard_rock, 80s, british   \n",
       "\n",
       "      genre  year  duration_ms  danceability  ...  instrumentalness  liveness  \\\n",
       "10000  Rock  2006       260066         0.579  ...          0.004010     0.286   \n",
       "10001   NaN  1986       247840         0.438  ...          0.000006     0.345   \n",
       "\n",
       "       valence    tempo  time_signature  \\\n",
       "10000    0.795  131.097               3   \n",
       "10001    0.347   75.054               3   \n",
       "\n",
       "                                         processed_audio  \\\n",
       "10000  ([-0.1274366, -0.21459332, -0.023305148, -0.08...   \n",
       "10001  ([0.09164546, 0.12546735, 0.06996889, 0.048958...   \n",
       "\n",
       "                                         augmented_audio  \\\n",
       "10000  ([-0.18257691, -0.3222155, -0.12718868, -0.017...   \n",
       "10001  ([0.080816284, 0.06832799, 0.08953604, 0.08095...   \n",
       "\n",
       "                                    diff_processed_audio   diff_artist  \\\n",
       "10000  ([-0.09010448, -0.13527939, -0.14203383, -0.09...       Mr. Big   \n",
       "10001  ([-0.059521385, -0.09814703, 0.0005738288, 0.0...  Eric Clapton   \n",
       "\n",
       "            diff_name  \n",
       "10000  To Be With You  \n",
       "10001         Alberta  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read audio from dataframe and add augmented column\n",
    "def augment_audio(row, which):\n",
    "    # Somewhat random assortment of small augmentations\n",
    "    augment = Compose([\n",
    "        AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "        TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "        PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "        Gain(min_gain_in_db=-5, max_gain_in_db=5, p=1.0),\n",
    "        AddGaussianSNR(min_snr_db=5.0, max_snr_db=10.0,p=1.0),\n",
    "        #Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "    ])\n",
    "    # Augment: row[which][0] is y, row[which][1] is sr\n",
    "    augmented_audio = augment(samples = row[which][0], sample_rate=row[which][1])\n",
    "    return augmented_audio, row[which][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cover song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the CNN model\n",
    "class AudioEmbeddingCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(AudioEmbeddingCNN, self).__init__()\n",
    "        # Define the CNN layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Define batch normalization layers\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Define the fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 32 * 32, 256)\n",
    "        self.fc2 = nn.Linear(256, embedding_dim)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass through convolutional layers with batch normalization and ReLU\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # Flatten the output from the conv layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Pass through fully connected layers with ReLU and dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        # Normalize the embedding to ensure unit length\n",
    "        return F.normalize(x, p=2, dim=1)\n",
    "\n",
    "# Instantiate the model, define loss function and optimizer\n",
    "embedding_dim = 128\n",
    "model = AudioEmbeddingCNN(embedding_dim=embedding_dim)\n",
    "\n",
    "# Triplet loss and optimizer\n",
    "criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, embedding_dim=128):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # Shared CNN model for both inputs\n",
    "        self.embedding_cnn = AudioEmbeddingCNN(embedding_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        # Pass both inputs through the shared embedding model\n",
    "        embed1 = self.embedding_cnn(x1)\n",
    "        embed2 = self.embedding_cnn(x2)\n",
    "        return embed1, embed2\n",
    "\n",
    "def contrastive_loss(output1, output2, label, margin=1.0):\n",
    "    # Calculate the Euclidean distance between the two outputs\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    # Contrastive loss calculation\n",
    "    loss = (1 - label) * torch.pow(euclidean_distance, 2) + \\\n",
    "           label * torch.pow(torch.clamp(margin - euclidean_distance, min=0.0), 2)\n",
    "    return loss.mean()\n",
    "\n",
    "# Instantiate the model, define optimizer\n",
    "embedding_dim = 128\n",
    "model = SiameseNetwork(embedding_dim=embedding_dim)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10  # Adjust as needed\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for (song1, song2, labels) in train_loader:\n",
    "        song1, song2, labels = song1.to(device), song2.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        embed1, embed2 = model(song1, song2)\n",
    "        \n",
    "        # Calculate contrastive loss\n",
    "        loss = contrastive_loss(embed1, embed2, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * song1.size(0)\n",
    "    \n",
    "    # Calculate and print the average loss for this epoch\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_may_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
