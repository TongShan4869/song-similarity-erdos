{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fine Tuning Resnet\n","- Create dataset class and instatiate dataloaders for batching large dataset on Kaggle\n","- Load in ResNet-18 weights from PyTorch library\n","- Allow for hyperparameter experimentation, including freezing/unfreezing layers.\n","- Plots training/validation loss curves\n","- Output log files, plot, and model weights for deployment"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T03:58:18.972797Z","iopub.status.busy":"2024-08-20T03:58:18.972348Z","iopub.status.idle":"2024-08-20T03:58:27.922843Z","shell.execute_reply":"2024-08-20T03:58:27.921149Z","shell.execute_reply.started":"2024-08-20T03:58:18.972760Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import librosa\n","import librosa.display\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import os\n","from dotenv import dotenv_values \n","import pickle as pkl\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","from torch.utils.data import DataLoader, Dataset\n","import torch.optim as optim\n","\n","from scipy.spatial.distance import euclidean\n","from sklearn.model_selection import train_test_split\n","from transformers import WhisperProcessor, WhisperForConditionalGeneration"]},{"cell_type":"markdown","metadata":{},"source":["#### Create Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T23:07:42.162162Z","iopub.status.busy":"2024-08-19T23:07:42.161610Z","iopub.status.idle":"2024-08-19T23:07:42.175092Z","shell.execute_reply":"2024-08-19T23:07:42.173872Z","shell.execute_reply.started":"2024-08-19T23:07:42.162129Z"},"trusted":true},"outputs":[],"source":["class SpectrogramDataset(Dataset):\n","    def __init__(self, file_paths, transform=False, sr=22050, n_mels=128):\n","        self.file_paths = file_paths\n","        self.data_index = self._build_index()\n","        self.sr = sr\n","        self.n_mels = n_mels\n","        self.transform = transform\n","        \n","    def _build_index(self):\n","        index = []\n","        for file_idx, file_path in enumerate(self.file_paths):\n","            with open(file_path, 'rb') as f:\n","                data = pkl.load(f)\n","                for i in range(len(data)):\n","                    index.append((file_idx, i))\n","        return index\n","\n","    def _get_log_mel_spectrogram(self, y):\n","        # Convert to mel spectrogram\n","        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=self.sr, n_mels=self.n_mels)\n","        # Convert to log scale\n","        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n","        log_mel_spectrogram = torch.tensor(log_mel_spectrogram, dtype=torch.float32).unsqueeze(0)\n","        return log_mel_spectrogram\n","\n","    def __len__(self):\n","        return len(self.data_index)\n","\n","    def __getitem__(self, idx):\n","        file_idx, data_idx = self.data_index[idx]\n","        file_path = self.file_paths[file_idx]\n","\n","        with open(file_path, 'rb') as f:\n","            data = pkl.load(f)\n","        \n","        row = data.iloc[data_idx]\n","        anchor = row['processed_audio'][0]  # (y, sr)\n","        positive = row['augmented_audio'][0]\n","        negative = row['diff_processed_audio'][0]\n","\n","        # Convert to log mel spectrograms\n","        anchor_mel = self._get_log_mel_spectrogram(anchor)\n","        positive_mel = self._get_log_mel_spectrogram(positive)\n","        negative_mel = self._get_log_mel_spectrogram(negative)\n","        \n","        # Apply any transformations\n","        if self.transform:\n","            anchors = self.transform(anchors)\n","            positives = self.transform(positives)\n","            negatives = self.transform(negatives)\n","\n","        return anchor_mel, positive_mel, negative_mel\n"]},{"cell_type":"markdown","metadata":{},"source":["### Split Data and Instantiate Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T23:07:42.176883Z","iopub.status.busy":"2024-08-19T23:07:42.176536Z","iopub.status.idle":"2024-08-19T23:10:34.029520Z","shell.execute_reply":"2024-08-19T23:10:34.026577Z","shell.execute_reply.started":"2024-08-19T23:07:42.176852Z"},"trusted":true},"outputs":[],"source":["file_paths = [f'/kaggle/input/augmented-audio-10k/batch_{i}_augmented.pkl' for i in range(1,10,1)]\n","\n","# Split the files instaed of actual data into training/val\n","train_files, val_files = train_test_split(file_paths, test_size=0.2, random_state=123)\n","\n","# Instantiate Dataset Classes\n","train_dataset = SpectrogramDataset(train_files)\n","val_dataset = SpectrogramDataset(val_files)\n","\n","# Declare dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)#, drop_last=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Delcaring the Model\n","- Define architecture: default resnet with adjusted first conv layer and final FC layer to set num params\n","- Choose loss function, optimizer, device, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-19T23:17:35.662549Z","iopub.status.busy":"2024-08-19T23:17:35.660307Z","iopub.status.idle":"2024-08-19T23:17:35.676843Z","shell.execute_reply":"2024-08-19T23:17:35.675637Z","shell.execute_reply.started":"2024-08-19T23:17:35.662501Z"},"trusted":true},"outputs":[],"source":["# Define pretrained resnet from Torch Vision resnet 18\n","class ResNetEmbedding(nn.Module):\n","    def __init__(self, embedding_dim=128, dropout_rate=0.5):\n","        # get resnet super class\n","        super(ResNetEmbedding, self).__init__()\n","        self.resnet = models.resnet18(weights='DEFAULT')\n","        # Change structure of first layer to take non RGB images, rest of params same as default\n","        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.dropout = nn.Dropout(p=dropout_rate)\n","        # Set the last fully connected to a set dimension \"embedding_dim\" instead of default 1000\n","        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, embedding_dim)\n","\n","    def forward(self, x):\n","        x = self.resnet(x)\n","        return F.normalize(x, p=2, dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-18T22:03:06.734510Z","iopub.status.busy":"2024-08-18T22:03:06.734192Z","iopub.status.idle":"2024-08-18T22:03:07.699445Z","shell.execute_reply":"2024-08-18T22:03:07.698532Z","shell.execute_reply.started":"2024-08-18T22:03:06.734480Z"},"trusted":true},"outputs":[],"source":["# Choose model, loss, and optimizer\n","model = ResNetEmbedding()\n","\n","criterion = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n","\n","# --- COMMENT OUT BELOW IF NOT FREEZING ----- #\n","# Freeze all the layers\n","for param in model.resnet.parameters():\n","    param.requires_grad = False\n","\n","# Turn back on last residual block\n","for param in model.resnet.layer4.parameters():\n","    param.requires_grad = True\n","\n","# Turn back on fully connected layer\n","for param in model.resnet.fc.parameters():\n","    param.requires_grad = True\n","\n","# Use a smaller learning rate for fine-tuning\n","optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n","# --- COMMENT OUT ABOVE IF NOT FREEZING --- #\n","\n","# Uncomment if not freezing\n","#optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4)\n","\n","# Declare losses/accuracies\n","train_losses = []\n","val_losses = []\n","baseline_losses = []\n","\n","num_epochs = 5\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-18T22:03:07.702434Z","iopub.status.busy":"2024-08-18T22:03:07.701882Z"},"trusted":true},"outputs":[],"source":["# Loop over epochs\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    running_train_loss = 0.0\n","    pbar = tqdm(train_loader, desc=f\"Training {epoch+1}/{num_epochs}\", unit=\"batch\")\n","\n","    # Loop over batches using dataloaders\n","    for anchors, positives, negatives in train_loader:\n","        anchors, positives, negatives = anchors.to(device), positives.to(device), negatives.to(device)\n","        optimizer.zero_grad()\n","        \n","        anchor_embeddings = model(anchors)\n","        positive_embeddings = model(positives)\n","        negative_embeddings = model(negatives)\n","        \n","        loss = criterion(anchor_embeddings, positive_embeddings, negative_embeddings)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_train_loss += loss.item() * anchors.size(0)\n","        pbar.update(1)\n","\n","          \n","    train_loss = running_train_loss / len(train_loader.dataset)\n","    train_losses.append(train_loss)\n","\n","    # Turn on validation/eval mode\n","    model.eval()\n","    running_val_loss = 0.0 \n","    running_baseline_loss = 0.0   \n","    val_pbar = tqdm(val_loader, desc=f\"Validation {epoch+1}/{num_epochs}\", unit=\"batch\")\n","    # Turn off gradient updates since we're in validation\n","    with torch.no_grad():\n","        # Batch loop \n","        for anchors, positives, negatives in tqdm(val_loader):\n","            anchors, positives, negatives = anchors.to(device), positives.to(device), negatives.to(device)\n","            \n","            anchor_embeddings = model(anchors)\n","            positive_embeddings = model(positives)\n","            negative_embeddings = model(negatives)\n","            \n","            loss = criterion(anchor_embeddings, positive_embeddings, negative_embeddings)\n","\n","            # Add to running val loss\n","            running_val_loss += loss.item() * anchors.size(0)\n","            \n","            # baseline loss\n","            baseline_loss = criterion(F.normalize(anchors), \n","                                               F.normalize(positives), \n","                                               F.normalize(negatives)).item()\n","            running_baseline_loss += baseline_loss*anchors.size(0)\n","            val_pbar.update(1) \n","\n","    \n","    # Calculate average validation loss over the entire dataset\n","    val_loss = running_val_loss / len(val_loader.dataset)\n","    val_losses.append(val_loss)\n","    # Do the same for the baseline\n","    baseline_avg_loss = running_baseline_loss / len(val_loader.dataset)\n","    baseline_losses.append(baseline_avg_loss)\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Baseline Loss: {baseline_avg_loss:.4f}\")\n","    \n","    with open('training_logs.pkl', 'wb') as f:\n","        pkl.dump((train_losses, val_losses, baseline_losses), f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:22:41.439153Z","iopub.status.idle":"2024-08-16T16:22:41.439602Z","shell.execute_reply":"2024-08-16T16:22:41.439427Z","shell.execute_reply.started":"2024-08-16T16:22:41.439403Z"},"trusted":true},"outputs":[],"source":["# Plot loss curves for training\n","epochs = range(1, num_epochs + 1)\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(epochs, train_losses, label='Training Loss')\n","plt.plot(epochs, val_losses, label='Validation Loss')\n","plt.plot(epochs, baseline_losses, label='Baseline Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.tight_layout()\n","plt.savefig('resnet-loss-plot.png')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:22:41.441097Z","iopub.status.idle":"2024-08-16T16:22:41.441510Z","shell.execute_reply":"2024-08-16T16:22:41.441321Z","shell.execute_reply.started":"2024-08-16T16:22:41.441304Z"},"trusted":true},"outputs":[],"source":["# Save just the model weights (recommended apparently for portability/compatibility)\n","torch.save(model.state_dict(), 'resnet18_model_weights.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:22:41.443645Z","iopub.status.idle":"2024-08-16T16:22:41.444030Z","shell.execute_reply":"2024-08-16T16:22:41.443869Z","shell.execute_reply.started":"2024-08-16T16:22:41.443852Z"},"trusted":true},"outputs":[],"source":["# Save the entire model so we can use it for deployment\n","torch.save(model, 'resnet18_model.pth')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5535463,"sourceId":9162188,"sourceType":"datasetVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
