{"cells":[{"cell_type":"markdown","metadata":{},"source":["# CNN From Scratch\n","- Prepare data for training/validation. Create dataloader\n","- Declare CNN model to craete embeddings\n","- Output parameters "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:02:12.067582Z","iopub.status.busy":"2024-08-20T20:02:12.067184Z","iopub.status.idle":"2024-08-20T20:02:19.813734Z","shell.execute_reply":"2024-08-20T20:02:19.812720Z","shell.execute_reply.started":"2024-08-20T20:02:12.067548Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import librosa\n","import librosa.display\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import os\n","from dotenv import dotenv_values \n","import pickle as pkl\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","from torch.utils.data import DataLoader, Dataset\n","import torch.optim as optim\n","\n","from scipy.spatial.distance import euclidean\n","from sklearn.model_selection import train_test_split\n","from transformers import WhisperProcessor, WhisperForConditionalGeneration"]},{"cell_type":"markdown","metadata":{},"source":["#### Create Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:02:19.816204Z","iopub.status.busy":"2024-08-20T20:02:19.815674Z","iopub.status.idle":"2024-08-20T20:02:19.828615Z","shell.execute_reply":"2024-08-20T20:02:19.827336Z","shell.execute_reply.started":"2024-08-20T20:02:19.816171Z"},"trusted":true},"outputs":[],"source":["class SpectrogramDataset(Dataset):\n","    def __init__(self, file_paths, transform=False, sr=22050, n_mels=128):\n","        self.file_paths = file_paths\n","        self.data_index = self._build_index()\n","        self.sr = sr\n","        self.n_mels = n_mels\n","        self.transform = transform\n","        \n","    def _build_index(self):\n","        index = []\n","        for file_idx, file_path in enumerate(self.file_paths):\n","            with open(file_path, 'rb') as f:\n","                data = pkl.load(f)\n","                for i in range(len(data)):\n","                    index.append((file_idx, i))\n","        return index\n","\n","    def _get_log_mel_spectrogram(self, y):\n","        # Convert to mel spectrogram\n","        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=self.sr, n_mels=self.n_mels)\n","        # Convert to log scale\n","        log_mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n","        log_mel_spectrogram = torch.tensor(log_mel_spectrogram, dtype=torch.float32).unsqueeze(0)\n","        return log_mel_spectrogram\n","\n","    def __len__(self):\n","        return len(self.data_index)\n","\n","    def __getitem__(self, idx):\n","        file_idx, data_idx = self.data_index[idx]\n","        file_path = self.file_paths[file_idx]\n","\n","        with open(file_path, 'rb') as f:\n","            data = pkl.load(f)\n","        \n","        row = data.iloc[data_idx]\n","        anchor = row['processed_audio'][0]  # (y, sr)\n","        positive = row['augmented_audio'][0]\n","        negative = row['diff_processed_audio'][0]\n","\n","        # Convert to log mel spectrograms\n","        anchor_mel = self._get_log_mel_spectrogram(anchor)\n","        positive_mel = self._get_log_mel_spectrogram(positive)\n","        negative_mel = self._get_log_mel_spectrogram(negative)\n","        \n","        # Apply any transformations\n","        if self.transform:\n","            anchors = self.transform(anchors)\n","            positives = self.transform(positives)\n","            negatives = self.transform(negatives)\n","\n","        return anchor_mel, positive_mel, negative_mel\n"]},{"cell_type":"markdown","metadata":{},"source":["### Split Data and Instantiate Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T20:02:19.831220Z","iopub.status.busy":"2024-08-20T20:02:19.830226Z","iopub.status.idle":"2024-08-20T20:04:21.149181Z","shell.execute_reply":"2024-08-20T20:04:21.146828Z","shell.execute_reply.started":"2024-08-20T20:02:19.831177Z"},"trusted":true},"outputs":[],"source":["file_paths = [f'/kaggle/input/augmented-audio-10k/batch_{i}_augmented.pkl' for i in range(1,10,1)]\n","\n","# Split the files instaed of actual data into training/val\n","train_files, val_files = train_test_split(file_paths, test_size=0.2, random_state=123)\n","\n","# Instantiate Dataset Classes\n","train_dataset = SpectrogramDataset(train_files)\n","val_dataset = SpectrogramDataset(val_files)\n","\n","# Declare dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)#, drop_last=True)"]},{"cell_type":"markdown","metadata":{},"source":["### Delcaring the Model\n","- Define architecture: standard CNN with batch norms and pooling to create 128 dim embeddings\n","- Choose loss function, optimizer, device, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-20T03:58:27.925782Z","iopub.status.busy":"2024-08-20T03:58:27.925139Z","iopub.status.idle":"2024-08-20T03:58:27.940319Z","shell.execute_reply":"2024-08-20T03:58:27.938876Z","shell.execute_reply.started":"2024-08-20T03:58:27.925744Z"},"trusted":true},"outputs":[],"source":["class MusicSimilarityCNN(nn.Module):\n","    def __init__(self, embedding_dim=128, dropout_rate=0.5):\n","        super(MusicSimilarityCNN, self).__init__()\n","        \n","        # Layers to get to 128 dim embeddings\n","        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n","        \n","        # Batch norm for each \n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        \n","        # Pooling\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","        \n","        # FCs\n","        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n","        self.fc2 = nn.Linear(256, embedding_dim)\n","        \n","    def forward(self, x):\n","        # CNN layers with ReLU activation and pooling\n","        x = self.pool(F.relu(self.bn1(self.conv1(x)))) # Conv -> BatchNorm -> Relu -> Pool\n","        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n","        \n","        # Flatten the output for the fully connected layer\n","        x = x.view(-1, 128 * 8 * 8)  # Adjust this according to the input size\n","        x = F.relu(self.fc1(x))\n","        \n","        # Output the embeddings\n","        x = self.fc2(x)\n","        return F.normalize(x, p=2, dim=1)  # Normalize embeddings for better similarity comparison\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-18T22:03:06.734510Z","iopub.status.busy":"2024-08-18T22:03:06.734192Z","iopub.status.idle":"2024-08-18T22:03:07.699445Z","shell.execute_reply":"2024-08-18T22:03:07.698532Z","shell.execute_reply.started":"2024-08-18T22:03:06.734480Z"},"trusted":true},"outputs":[],"source":["# Choose model, loss, and optimizer\n","model = MusicSimilarityCNN()\n","criterion = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n","optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4)\n","\n","# Declare losses/accuracies\n","train_losses = []\n","val_losses = []\n","baseline_losses = []\n","\n","num_epochs = 16\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-18T22:03:07.702434Z","iopub.status.busy":"2024-08-18T22:03:07.701882Z"},"trusted":true},"outputs":[],"source":["# Loop over epochs\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    running_train_loss = 0.0\n","    pbar = tqdm(train_loader, desc=f\"Training {epoch+1}/{num_epochs}\", unit=\"batch\")\n","\n","    # Loop over batches using dataloaders\n","    for anchors, positives, negatives in train_loader:\n","        anchors, positives, negatives = anchors.to(device), positives.to(device), negatives.to(device)\n","        optimizer.zero_grad()\n","        \n","        anchor_embeddings = model(anchors)\n","        positive_embeddings = model(positives)\n","        negative_embeddings = model(negatives)\n","        \n","        loss = criterion(anchor_embeddings, positive_embeddings, negative_embeddings)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_train_loss += loss.item() * anchors.size(0)\n","        pbar.update(1)\n","          \n","    train_loss = running_train_loss / len(train_loader.dataset)\n","    train_losses.append(train_loss)\n","\n","    # Turn on validation/eval mode\n","    model.eval()\n","    running_val_loss = 0.0 \n","    running_baseline_loss = 0.0   \n","    val_pbar = tqdm(val_loader, desc=f\"Validation {epoch+1}/{num_epochs}\", unit=\"batch\")\n","    \n","    # Turn off gradient updates since we're in validation\n","    with torch.no_grad():\n","        # Batch loop \n","        for anchors, positives, negatives in tqdm(val_loader):\n","            anchors, positives, negatives = anchors.to(device), positives.to(device), negatives.to(device)\n","            \n","            anchor_embeddings = model(anchors)\n","            positive_embeddings = model(positives)\n","            negative_embeddings = model(negatives)\n","            \n","            loss = criterion(anchor_embeddings, positive_embeddings, negative_embeddings)\n","\n","            # Add to running val loss\n","            running_val_loss += loss.item() * anchors.size(0)\n","            \n","            # baseline loss\n","            baseline_loss = criterion(F.normalize(anchors), \n","                                               F.normalize(positives), \n","                                               F.normalize(negatives)).item()\n","            running_baseline_loss += baseline_loss*anchors.size(0)\n","            \n","            # Update the validation progress bar\n","            val_pbar.update(1)\n","\n","    \n","    # Calculate average validation loss over the entire dataset\n","    val_loss = running_val_loss / len(val_loader.dataset)\n","    val_losses.append(val_loss)\n","    # Do the same for the baseline\n","    baseline_avg_loss = running_baseline_loss / len(val_loader.dataset)\n","    baseline_losses.append(baseline_avg_loss)\n","\n","    \n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Baseline Loss: {baseline_avg_loss:.4f}\")\n","    \n","    with open('training_logs.pkl', 'wb') as f:\n","        pkl.dump((train_losses, val_losses), f)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:22:41.439153Z","iopub.status.idle":"2024-08-16T16:22:41.439602Z","shell.execute_reply":"2024-08-16T16:22:41.439427Z","shell.execute_reply.started":"2024-08-16T16:22:41.439403Z"},"trusted":true},"outputs":[],"source":["# Plot loss curves for training\n","epochs = range(1, num_epochs + 1)\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(epochs, train_losses, label='Training Loss')\n","plt.plot(epochs, val_losses, label='Validation Loss')\n","plt.plot(epochs, baseline_losses, label='Baseline Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.tight_layout()\n","plt.savefig('cnn-loss-plot.png')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:22:41.441097Z","iopub.status.idle":"2024-08-16T16:22:41.441510Z","shell.execute_reply":"2024-08-16T16:22:41.441321Z","shell.execute_reply.started":"2024-08-16T16:22:41.441304Z"},"trusted":true},"outputs":[],"source":["# Save just the model weights (recommended apparently for portability/compatibility)\n","torch.save(model.state_dict(), 'cnn_model_weights.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-16T16:22:41.443645Z","iopub.status.idle":"2024-08-16T16:22:41.444030Z","shell.execute_reply":"2024-08-16T16:22:41.443869Z","shell.execute_reply.started":"2024-08-16T16:22:41.443852Z"},"trusted":true},"outputs":[],"source":["# Save the entire model so we can use it for deployment\n","torch.save(model, 'cnn_model.pth')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5535463,"sourceId":9162188,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
