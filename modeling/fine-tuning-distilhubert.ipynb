{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9020098,"sourceType":"datasetVersion","datasetId":5435569}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q transformers datasets torchaudio","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport requests\nimport io\nfrom IPython.display import Audio, display\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport os\nimport re","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge datasets to get spotify links for most similar and most different song","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Wav2Vec2Processor, DistilHuBERTForSequenceClassification\nfrom datasets import load_dataset\nimport torch\n\nprocessor = Wav2Vec2Processor.from_pretrained(\"facebook/distilhubert-base\")\nmodel = DistilHuBERTForSequenceClassification.from_pretrained(\"facebook/distilhubert-base\", num_labels=2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_function(examples):\n    audio = examples[\"audio\"]\n    inputs = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\", padding=True)\n    return inputs\n\ndataset = load_dataset(\"path/to/your/dataset\")\ndataset = dataset.map(preprocess_function)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    tokenizer=processor.feature_extractor,\n)\n\ntrainer.train()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def measure_similarity(file1, file2, model, processor):\n    y1, sr1 = load_audio(file1)\n    y2, sr2 = load_audio(file2)\n    \n    inputs1 = processor(y1, sampling_rate=sr1, return_tensors=\"pt\", padding=True)\n    inputs2 = processor(y2, sampling_rate=sr2, return_tensors=\"pt\", padding=True)\n    \n    with torch.no_grad():\n        outputs1 = model(**inputs1).logits\n        outputs2 = model(**inputs2).logits\n        \n    euclidean_distance = torch.nn.functional.pairwise_distance(outputs1, outputs2)\n    return euclidean_distance.item()\n\nsimilarity_score = measure_similarity('audio1.wav', 'audio2.wav', model, processor)\nprint(f\"Similarity score: {similarity_score}\")\n","metadata":{},"execution_count":null,"outputs":[]}]}