{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Fine Tuning DistilHuBERT\n","- Fine tune transformer architecture\n","- Make binary classification with similar, dissimilar pairs."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import librosa\n","import librosa.display\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import os\n","from dotenv import dotenv_values \n","import spotipy\n","from spotipy.oauth2 import SpotifyClientCredentials\n","import pickle as pkl\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.models as models\n","from torch.utils.data import DataLoader, Dataset\n","\n","from scipy.spatial.distance import euclidean\n","from sklearn.model_selection import train_test_split\n","\n","from transformers import Wav2Vec2Processor, DistilHuBERTForSequenceClassification, Wav2Vec2Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Dataset class that does include batching same as for other model.\n","class SpectrogramDataset(Dataset):\n","\n","    def __init__(self, file_paths, sr=22050, n_mels=128):\n","        self.file_paths = file_paths\n","        self.current_file_index = 0\n","\n","        self.sr = sr\n","        self.n_mels = n_mels\n","        self.load_current_file()      \n","    \n","    def load_current_file(self):\n","        # Load data from the current .pkl file\n","        self.current_data = pd.read_pickle(self.file_paths[self.current_file_index])\n","        self.current_anchors = self.current_data['processed_audio'].values\n","        self.current_positives = self.current_data['augmented_audio'].values\n","        self.current_negatives = self.current_data['diff_processed_audio'].values\n","        self.current_file_length = len(self.current_anchors)\n","        self.current_file_index += 1\n","    \n","    def __len__(self):\n","        total_length = sum(pd.read_pickle(file).shape[0] for file in self.file_paths)\n","        return total_length\n","    \n","    def __getitem__(self, idx):\n","        while idx >= self.current_file_length:\n","            idx -= self.current_file_length\n","            if self.current_file_index < len(self.file_paths):\n","                self.load_current_file()\n","            else:\n","                raise IndexError(\"Index out of range\")\n","\n","        # Load audio data and select idx'th example and get [0] to get audio from (y, sr) tuple\n","        anchor = self.current_anchors[idx][0]\n","        positive = self.current_positives[idx][0]\n","        negative = self.current_negatives[idx][0]\n","\n","        # Compute mel spectrograms\n","        anchor_mel = self._process_audio(anchor)\n","        positive_mel = self._process_audio(positive)\n","        negative_mel = self._process_audio(negative)\n","\n","        return anchor_mel, positive_mel, negative_mel\n","    \n","    # Convert raw audio to mel spectrogram\n","    def _process_audio(self, y):\n","        mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=self.sr, n_mels=self.n_mels)\n","        mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n","        mel_spectrogram_db = torch.tensor(mel_spectrogram_db, dtype=torch.float32).unsqueeze(0)\n","        return mel_spectrogram_db"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class SimilarityModel(nn.Module):\n","    def __init__(self, pretrained_model_name='facebook/distilhubert'):\n","        super(SimilarityModel, self).__init__()\n","        self.model = Wav2Vec2Model.from_pretrained(pretrained_model_name)\n","        self.fc = nn.Linear(self.model.config.hidden_size, 128)\n","\n","    def forward(self, anchor, positive, negative):\n","        anchor_output = self.model(anchor).last_hidden_state\n","        positive_output = self.model(positive).last_hidden_state\n","        negative_output = self.model(negative).last_hidden_state\n","\n","        anchor_output = self.fc(anchor_output.mean(dim=1))\n","        positive_output = self.fc(positive_output.mean(dim=1))\n","        negative_output = self.fc(negative_output.mean(dim=1))\n","\n","        return anchor_output, positive_output, negative_output\n","\n","# Example initialization\n","model = SimilarityModel()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["file_paths = [f'../data/augmented_audio/batch_{i}_augmented.pkl' for i in range(1,3,1)]\n","\n","# Split the files instaed of actual data into training/val\n","train_files, val_files = train_test_split(file_paths, test_size=0.2, random_state=123)\n","\n","# Instantiate Dataset Classes\n","train_dataset = SpectrogramDataset(train_files)\n","val_dataset = SpectrogramDataset(val_files)\n","\n","# Declare dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Choose model, loss, and optimizer\n","model = ResNetEmbedding()\n","criterion = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-7)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","# Declare losses/accuracies\n","train_losses = []\n","val_losses = []\n","\n","num_epochs = 1\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Merge datasets to get spotify links for most similar and most different song"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import Wav2Vec2Processor, DistilHuBERTForSequenceClassification\n","from datasets import load_dataset\n","import torch\n","\n","processor = Wav2Vec2Processor.from_pretrained(\"facebook/distilhubert-base\")\n","model = DistilHuBERTForSequenceClassification.from_pretrained(\"facebook/distilhubert-base\", num_labels=2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def preprocess_function(examples):\n","    audio = examples[\"audio\"]\n","    inputs = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\", padding=True)\n","    return inputs\n","\n","dataset = load_dataset(\"path/to/your/dataset\")\n","dataset = dataset.map(preprocess_function)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import TrainingArguments, Trainer\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    tokenizer=processor.feature_extractor,\n",")\n","\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def measure_similarity(file1, file2, model, processor):\n","    y1, sr1 = load_audio(file1)\n","    y2, sr2 = load_audio(file2)\n","    \n","    inputs1 = processor(y1, sampling_rate=sr1, return_tensors=\"pt\", padding=True)\n","    inputs2 = processor(y2, sampling_rate=sr2, return_tensors=\"pt\", padding=True)\n","    \n","    with torch.no_grad():\n","        outputs1 = model(**inputs1).logits\n","        outputs2 = model(**inputs2).logits\n","        \n","    euclidean_distance = torch.nn.functional.pairwise_distance(outputs1, outputs2)\n","    return euclidean_distance.item()\n","\n","similarity_score = measure_similarity('audio1.wav', 'audio2.wav', model, processor)\n","print(f\"Similarity score: {similarity_score}\")\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5435569,"sourceId":9020098,"sourceType":"datasetVersion"}],"dockerImageVersionId":30746,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
