{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy on any 2 songs\n",
    "- Use model to calculate embeddings (using eval mode specifically and with no gradient updating)\n",
    "- NOTE: Right now, we have to have the input data in the correct format: a spectrogram/chromagram/tempogram (generically called \"gram\"). So for any deployment, we'll have to do preprocessing in the streamlit app for example. OR we can have a set of say 10-15 sample songs you can compare where we've already done all of the calculations.\n",
    "- **Similarity values key:**\n",
    "    - 0.5 to 1: Very similar. Perhaps the same song.\n",
    "    - 0 to 0.5: Somewhat similar. Share some key characteristics\n",
    "    - -1 to 0: Low to no similarity. Different songs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the model\n",
    "model = torch.load('full_model.pth')\n",
    "model.eval()  # Set to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model to the appropriate device (if using GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to load the model later\n",
    "#model = ResNetEmbedding()  # Make sure this matches the architecture you used\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "#model.load_state_dict(torch.load('resnet18_model_weights.pth'))\n",
    "\n",
    "# If using a GPU\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def extract_embedding(model, audio_data_clip, sr=22050):\n",
    "    # Load the audio file\n",
    "    y, sr = librosa.load(audio_data_clip, sr=sr)\n",
    "    \n",
    "    # Convert raw audio to mel spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr)\n",
    "    mel_spectrogram_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    # Convert to tensor and move to the appropriate device\n",
    "    mel_tensor = torch.tensor(mel_spectrogram_db, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get the embedding from the model\n",
    "    with torch.no_grad():\n",
    "        embedding = model(mel_tensor)\n",
    "    \n",
    "    # Normalize the embedding\n",
    "    embedding = F.normalize(embedding, p=2, dim=1)\n",
    "    \n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def compute_cosine_similarity(embedding1, embedding2):\n",
    "    # Compute cosine similarity\n",
    "    cosine_sim = F.cosine_similarity(embedding1, embedding2)\n",
    "    return cosine_sim.item()  # Convert to a Python float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the audio files (these should be the paths to your actual song files)\n",
    "anchor = '/Users/reggiebain/erdos/song-similarity-erdos-old/data/coversongs/covers32k/A_Whiter_Shade_Of_Pale/annie_lennox+Medusa+03-A_Whiter_Shade_Of_Pale.mp3'\n",
    "positive = '/Users/reggiebain/erdos/song-similarity-erdos-old/data/coversongs/covers32k/A_Whiter_Shade_Of_Pale/procol_harum+Greatest_Hits+2-A_Whiter_Shade_Of_Pale.mp3'\n",
    "negative = '/Users/reggiebain/erdos/song-similarity-erdos-old/data/coversongs/covers32k/Abracadabra/steve_miller_band+Steve_Miller_Band_Live_+09-Abracadabra.mp3'\n",
    "\n",
    "# Extract embeddings for both songs\n",
    "embedding1 = extract_embedding(model, audio_clip1)\n",
    "embedding2 = extract_embedding(model, audio_clip2)\n",
    "\n",
    "# Calculate cosine similarity between the two embeddings\n",
    "similarity = compute_cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "print(f\"Cosine Similarity between the two songs: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Spotify for Track to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stuff from .env file\n",
    "env_vars = dotenv_values('.env')\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(\n",
    "    client_id=os.getenv(\"SPOTIFY_CLIENT_ID\"),\n",
    "    client_secret=os.getenv(\"SPOTIFY_CLIENT_SECRET\"),\n",
    ")\n",
    "# Get Spotify api client and apply to df\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the preview URL of a song based on artist name and song title\n",
    "#@retry(wait=wait_exponential(multiplier=1, min=4, max=60), stop=stop_after_attempt(10))\n",
    "def search_track(artist_name, track_name, sp, rate_limit = 1.0):\n",
    "    # Search for the track\n",
    "    result = sp.search(q=f'artist:{artist_name} track:{track_name}', type='track', limit=1)\n",
    "    if result['tracks']['items']:\n",
    "        # Return the preview URL if found\n",
    "        return result['tracks']['items'][0]['preview_url']\n",
    "    print('Arist/Track not found...')\n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track1_name = 'Rosanna'\n",
    "track1_artist = 'Toto'\n",
    "track2_name = 'Rosanna'\n",
    "track2_artist = 'Toto'\n",
    "track1 = search_track(track1_artist, track1_name, sp)\n",
    "track2 = search_track(track1_artist, track1_name, sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_name = 'Toto'\n",
    "track_name = 'Rosanna'\n",
    "result = sp.search(q=f'artist:{artist_name} track:{track_name}', type='track', limit=1)\n",
    "result['tracks']['items'][0]['preview_url']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
